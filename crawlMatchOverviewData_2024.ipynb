{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def get_season_match_urls(base_url, session):\n",
    "    \"\"\"Fetch match URLs for the specified season.\"\"\"\n",
    "    response = session.get(base_url, timeout=10)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to retrieve data from {base_url}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    match_links = []\n",
    "\n",
    "    # Find all match links from the provided season's page\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        href = link['href']\n",
    "        if \"/spielbericht/\" in href:\n",
    "            match_links.append(f\"https://www.transfermarkt.com{href}\")\n",
    "\n",
    "    return match_links\n",
    "\n",
    "def process_match_url(_match_url, session):\n",
    "    data = {\n",
    "        \"Match ID\": None,\n",
    "        \"Date\": None,\n",
    "        \"Season\": None,\n",
    "        \"Stadium\": None,\n",
    "        \"Number of Attendance\": None,\n",
    "        \"Referee\": None,\n",
    "        \"Home Team\": \"Unknown\",\n",
    "        \"Away Team\": \"Unknown\",\n",
    "        \"Home Lineup\": None,\n",
    "        \"Away Lineup\": None,\n",
    "        \"Fulltime Score\": \"Unknown\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = session.get(_match_url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data from {_match_url}\")\n",
    "            return data\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Match ID\n",
    "        match_id = _match_url.rstrip('/').split(\"/\")[-1]\n",
    "        data[\"Match ID\"] = str(match_id)\n",
    "\n",
    "        # Date\n",
    "        date_tag = soup.find(\"p\", class_=\"sb-datum hide-for-small\")\n",
    "        if date_tag:\n",
    "            date_links = date_tag.find_all(\"a\")\n",
    "            if date_links:\n",
    "                date_text = date_links[-1].text.strip()\n",
    "\n",
    "                try:\n",
    "                    match_date = datetime.strptime(date_text, \"%a, %m/%d/%y\").date()\n",
    "                    data[\"Date\"] = match_date\n",
    "\n",
    "                    # Season\n",
    "                    year = match_date.year\n",
    "                    season = f\"{str(year - 1)[-2:]}/{str(year)[-2:]}\" if match_date.month <= 7 else f\"{str(year)[-2:]}/{str(year + 1)[-2:]}\"\n",
    "                    data[\"Season\"] = season\n",
    "                except ValueError:\n",
    "                    print(f\"Date format error for Match ID {match_id}: '{date_text}'\")\n",
    "\n",
    "        # Stadium, Attendance, Referee\n",
    "        stadium_tag = soup.find(\"p\", class_=\"sb-zusatzinfos\")\n",
    "        if stadium_tag:\n",
    "            stadium_link = stadium_tag.find(\"a\", href=lambda href: href and \"/stadion/\" in href)\n",
    "            if stadium_link:\n",
    "                data[\"Stadium\"] = stadium_link.text.strip()\n",
    "\n",
    "            attendance_text = stadium_tag.find(\"strong\", text=lambda text: text and \"Attendance:\" in text.parent.text)\n",
    "            if attendance_text:\n",
    "                attendance_raw = attendance_text.parent.text.strip()\n",
    "                attendance = attendance_raw.split(\":\")[-1].replace(\".\", \"\").strip()\n",
    "                data[\"Number of Attendance\"] = attendance\n",
    "\n",
    "            referee_link = stadium_tag.find(\"a\", href=lambda href: href and \"/profil/schiedsrichter/\" in href)\n",
    "            if referee_link:\n",
    "                data[\"Referee\"] = referee_link.text.strip()\n",
    "\n",
    "        # Home and Away Team Names\n",
    "        home_team_tag = soup.select_one('.sb-team.sb-heim .sb-vereinslink')\n",
    "        away_team_tag = soup.select_one('.sb-team.sb-gast .sb-vereinslink')\n",
    "        if home_team_tag:\n",
    "            data[\"Home Team\"] = home_team_tag.get_text(strip=True)\n",
    "        if away_team_tag:\n",
    "            data[\"Away Team\"] = away_team_tag.get_text(strip=True)\n",
    "\n",
    "        # Full-Time Score\n",
    "        full_timescore_tag = soup.select_one('.sb-endstand')\n",
    "        if full_timescore_tag:\n",
    "            full_timescore = full_timescore_tag.get_text(strip=True)\n",
    "            match = re.match(r'^(\\d+):(\\d+)', full_timescore)\n",
    "            if match:\n",
    "                main_score = match.group(0)\n",
    "                data[\"Fulltime Score\"] = main_score\n",
    "            else:\n",
    "                data[\"Fulltime Score\"] = full_timescore.split('(')[0].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {_match_url}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def determine_winner(row):\n",
    "    try:\n",
    "        home_score, away_score = map(int, row[\"Fulltime Score\"].split(\":\"))\n",
    "        if home_score > away_score:\n",
    "            return row[\"Home Team\"]\n",
    "        elif home_score < away_score:\n",
    "            return row[\"Away Team\"]\n",
    "        else:\n",
    "            return \"Draw\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def scrape_all_match_overview(base_url, headers, max_workers=15):\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    # Step 1: Get all match URLs for the specified season\n",
    "    match_urls = get_season_match_urls(base_url, session)\n",
    "\n",
    "    # Step 2: Use ThreadPoolExecutor for multithreading\n",
    "    matches = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_match_url, url, session): url for url in match_urls}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                match_data = future.result()\n",
    "                # Exclude matches with missing date or fulltime score\n",
    "                if match_data[\"Date\"] and match_data[\"Fulltime Score\"] != \"Unknown\":\n",
    "                    matches.append(match_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL: {e}\")\n",
    "\n",
    "    session.close()\n",
    "\n",
    "    # Step 3: Create DataFrame\n",
    "    match_df = pd.DataFrame(matches)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    match_df = match_df.drop(columns=[\"Stadium\", \"Number of Attendance\", \"Referee\"])\n",
    "\n",
    "    # Add Winner column\n",
    "    match_df[\"Winner\"] = match_df.apply(determine_winner, axis=1)\n",
    "\n",
    "    return match_df\n",
    "\n",
    "# Main execution\n",
    "base_url = \"https://www.transfermarkt.com/premier-league/gesamtspielplan/wettbewerb/GB1/saison_id/2024\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "output_csv = \"./data/clean_data/match_overview_2024.csv\"\n",
    "match_overview_df = scrape_all_match_overview(base_url, headers, max_workers=10)\n",
    "match_overview_df.to_csv(output_csv, index=False, encoding='utf-8', header=True)\n",
    "print(\"Scraping complete. Data saved to\", output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
